{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Deep Q-Network Learning_\n",
    "## with Lunar Lander by OpenAI Gym\n",
    "\n",
    "In this project, it will train an agent to land a lunar lander safely on a landing pad on the surface of the moon.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Packages\n",
    "First, import all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "\n",
    "from pyvirtualdisplay import Display\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.losses import MSE\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a virtual display to render the Lunar Lander environment\n",
    "# Display(visible=0, size=(840, 480)).start()\n",
    "\n",
    "# set the random seed for TensorFlow\n",
    "tf.random.set_seed(utils.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMORY_SIZE = 100_000     # size of memory buffer\n",
    "GAMMA = 0.995             # discount factor\n",
    "ALPHA = 1e-3              # learning rate  \n",
    "NUM_STEPS_FOR_UPDATE = 4  # perform a learning update every C time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2', render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.00185976,  1.4221803 , -0.18839662,  0.5004553 ,  0.00216186,\n",
       "         0.04267462,  0.        ,  0.        ], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "# PIL.Image.fromarray(env.render(mode='rgb_array'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Shape = (8,)\n",
      "Number of Actions = 4\n"
     ]
    }
   ],
   "source": [
    "state_size = env.observation_space.shape\n",
    "num_actions = env.action_space.n\n",
    "\n",
    "print(f\"State Shape = {state_size}\")\n",
    "print(f\"Number of Actions = {num_actions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State\t\t: (array([0.004, 1.414, 0.365, 0.125, -0.004, -0.083, 0.000, 0.000],\n",
      "      dtype=float32), {})\n",
      "Action\t\t\t: 0\n",
      "Next State\t\t: [0.043 1.405 0.365 -0.167 -0.049 -0.082 0.000 0.000]\n",
      "Reward Received\t\t: -1.0802451748785984\n",
      "Episode Terminated\t: False\n",
      "Info\t\t\t: {}\n"
     ]
    }
   ],
   "source": [
    "# select the action\n",
    "action = 0\n",
    "\n",
    "# run a single time step of the environment's dynamics with the given action\n",
    "next_state, reward, done, _, info = env.step(action)\n",
    "\n",
    "with np.printoptions(formatter={'float': '{:.3f}'.format}):\n",
    "  print(f\"Initial State\\t\\t: {initial_state}\")\n",
    "  print(f\"Action\\t\\t\\t: {action}\")\n",
    "  print(f\"Next State\\t\\t: {next_state}\")\n",
    "  print(f\"Reward Received\\t\\t: {reward}\")\n",
    "  print(f\"Episode Terminated\\t: {done}\")\n",
    "  print(f\"Info\\t\\t\\t: {info}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
